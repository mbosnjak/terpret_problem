{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100.,  99.,  99.,  50.,   1.,   1.,   1.,   1.,   2.,  50.,  99.,  99.,\n",
       "         99.,  99.,  50.,   1.,   1.,  50.,  99.,  99.,  99.,  99.,  99.,  99.,\n",
       "         99.,  99.,  99.,  99.,  99.,  99.,  99.], grad_fn=<RoundBackward>)"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = torch.randn(k,  requires_grad=True)\n",
    "optimizer = torch.optim.SGD([mu], lr=1e-2)\n",
    "for t in range(0,10000):\n",
    "    x = torch.cat((torch.tensor([1.0]), torch.sigmoid(mu)))\n",
    "    z = torch.cat((x[-1:], x[:-1])) \n",
    "    equi = x * z + (1-x) * (1-z)\n",
    "    all_equi = torch.prod(equi)\n",
    "    loss = -torch.log(all_equi)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "torch.round(x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.randn(k,  requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0604, grad_fn=<NegBackward>),\n",
       " tensor([100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "         100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100., 100.,\n",
       "         100., 100., 100., 100., 100., 100., 100.], grad_fn=<RoundBackward>))"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD([mu], lr=1e-2)\n",
    "for t in range(0,10000):\n",
    "    x = torch.cat((torch.tensor([1.0]), torch.sigmoid(mu)))\n",
    "    all_equi = torch.prod(x) + torch.prod(1.0 - x)\n",
    "    loss = -torch.log(all_equi)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "loss, torch.round(x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.6635e-10, grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = torch.randn(k,  requires_grad=True)\n",
    "x = torch.cat((torch.tensor([1.0]), torch.sigmoid(mu)))\n",
    "\n",
    "def compute_all_equi(x):\n",
    "    all_equi_true = 1.0\n",
    "    all_equi_false = 1.0\n",
    "    for i in range(0,k+1):\n",
    "        prev = i-1 % k\n",
    "        all_equi_dumb = all_equi * ((x[i] * x[prev]) + (1-x[i]) * (1-x[prev]))\n",
    "        all_equi_true = all_equi_true * x[i]\n",
    "        all_equi_false = all_equi_false * (1-x[i])\n",
    "    return all_equi_false + all_equi_true\n",
    "compute_all_equi(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2546, grad_fn=<NegBackward>),\n",
       " tensor([100.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,\n",
       "          99.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,  99.,\n",
       "          99.,  99.,  99.,  99.,  99.,  99.,  99.], grad_fn=<RoundBackward>))"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD([mu], lr=1e-1)\n",
    "for t in range(0,100):\n",
    "    x = torch.cat((torch.tensor([1.0]), torch.sigmoid(mu)))\n",
    "#     print(x)\n",
    "    all_equi = compute_all_equi(x)\n",
    "    loss = -torch.log(all_equi)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     print(loss)\n",
    "\n",
    "loss, torch.round(x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2000861167907715\n",
      "1 3.196314573287964\n",
      "2 3.1925437450408936\n",
      "3 3.1887729167938232\n",
      "4 3.1850016117095947\n",
      "5 3.181230306625366\n",
      "6 3.1774587631225586\n",
      "7 3.173686981201172\n",
      "8 3.169914484024048\n",
      "9 3.166141986846924\n",
      "10 3.1623682975769043\n",
      "11 3.1585938930511475\n",
      "12 3.1548187732696533\n",
      "13 3.151042938232422\n",
      "14 3.147265672683716\n",
      "15 3.1434876918792725\n",
      "16 3.1397082805633545\n",
      "17 3.135927200317383\n",
      "18 3.1321451663970947\n",
      "19 3.128361225128174\n",
      "20 3.1245763301849365\n",
      "21 3.120788812637329\n",
      "22 3.116999864578247\n",
      "23 3.1132092475891113\n",
      "24 3.1094162464141846\n",
      "25 3.105621337890625\n",
      "26 3.1018242835998535\n",
      "27 3.09802508354187\n",
      "28 3.0942232608795166\n",
      "29 3.090419292449951\n",
      "30 3.0866124629974365\n",
      "31 3.082803249359131\n",
      "32 3.078991413116455\n",
      "33 3.075176477432251\n",
      "34 3.0713589191436768\n",
      "35 3.067538022994995\n",
      "36 3.0637142658233643\n",
      "37 3.059887409210205\n",
      "38 3.0560572147369385\n",
      "39 3.0522236824035645\n",
      "40 3.048387050628662\n",
      "41 3.044546604156494\n",
      "42 3.0407028198242188\n",
      "43 3.036855459213257\n",
      "44 3.03300404548645\n",
      "45 3.029149055480957\n",
      "46 3.02528977394104\n",
      "47 3.0214269161224365\n",
      "48 3.017559766769409\n",
      "49 3.013688564300537\n",
      "50 3.0098135471343994\n",
      "51 3.0059337615966797\n",
      "52 3.0020499229431152\n",
      "53 2.998161792755127\n",
      "54 2.9942686557769775\n",
      "55 2.9903712272644043\n",
      "56 2.986469268798828\n",
      "57 2.98256254196167\n",
      "58 2.9786510467529297\n",
      "59 2.974734306335449\n",
      "60 2.970813512802124\n",
      "61 2.9668869972229004\n",
      "62 2.9629554748535156\n",
      "63 2.959019184112549\n",
      "64 2.955077648162842\n",
      "65 2.9511308670043945\n",
      "66 2.947178602218628\n",
      "67 2.943221092224121\n",
      "68 2.939258098602295\n",
      "69 2.9352898597717285\n",
      "70 2.9313156604766846\n",
      "71 2.9273359775543213\n",
      "72 2.9233508110046387\n",
      "73 2.9193601608276367\n",
      "74 2.915363311767578\n",
      "75 2.911360740661621\n",
      "76 2.9073524475097656\n",
      "77 2.9033381938934326\n",
      "78 2.899317979812622\n",
      "79 2.895291805267334\n",
      "80 2.8912596702575684\n",
      "81 2.887220859527588\n",
      "82 2.883176326751709\n",
      "83 2.8791258335113525\n",
      "84 2.8750686645507812\n",
      "85 2.8710055351257324\n",
      "86 2.8669357299804688\n",
      "87 2.8628599643707275\n",
      "88 2.8587772846221924\n",
      "89 2.854688882827759\n",
      "90 2.8505935668945312\n",
      "91 2.846492052078247\n",
      "92 2.842383861541748\n",
      "93 2.8382692337036133\n",
      "94 2.8341474533081055\n",
      "95 2.830019474029541\n",
      "96 2.8258848190307617\n",
      "97 2.8217434883117676\n",
      "98 2.8175954818725586\n",
      "99 2.813441038131714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0602, grad_fn=<ProdBackward1>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_equi(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1128), tensor(0.0531))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_12 = x[0] * x[1] + (1-x[0])*(1 - x[1])\n",
    "eq_12_true = x[0] * x[1]\n",
    "eq_12_false = (1-x[0]) * (1-x[1])\n",
    "eq_123_true =  eq_12_true * x[2]\n",
    "eq_123_false = eq_12_false * (1-x[2])\n",
    "eq_23_true = x[1] * x[2]\n",
    "eq_23_false = (1-x[1])*(1-x[2])\n",
    "eq_123_true, eq_12_true * eq_23_true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
